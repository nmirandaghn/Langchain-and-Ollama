{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Langchain Expression Language Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  LangChain Expression Language is that any two runnables can be \"chained\" together into sequences. \n",
    "- The output of the previous runnable's .invoke() call is passed as input to the next runnable.\n",
    "- This can be done using the pipe operator (|), or the more explicit .pipe() method, which does the same thing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Type of LCEL Chains\n",
    "    - SequentialChain\n",
    "    - Parallel Chain\n",
    "    - Router Chain\n",
    "    - Chain Runnables\n",
    "    - Custom Chain (Runnable Sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('./../.env')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential LCEL Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOllama(model='llama3.2:1b', base_url='http://localhost:11434')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import (\n",
    "                                        SystemMessagePromptTemplate,\n",
    "                                        HumanMessagePromptTemplate,\n",
    "                                        PromptTemplate,\n",
    "                                        ChatPromptTemplate\n",
    "                                        )\n",
    "\n",
    "base_url = \"http://localhost:11434\"\n",
    "model = 'llama3.2:1b'\n",
    "\n",
    "llm = ChatOllama(base_url=base_url, model=model)\n",
    "\n",
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = SystemMessagePromptTemplate.from_template('You are {school} teacher. You answer in short sentences.')\n",
    "\n",
    "question = HumanMessagePromptTemplate.from_template('tell me about the {topics} in {points} points')\n",
    "\n",
    "messages = [system, question]\n",
    "template = ChatPromptTemplate(messages)\n",
    "\n",
    "# question = template.invoke({'school': 'primary', 'topics': 'solar system', 'points': 5})\n",
    "\n",
    "# response = llm.invoke(question)\n",
    "# print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a brief overview of the solar system:\n",
      "\n",
      "1. The Sun is at the center, and it makes up 99% of the total mass.\n",
      "2. The four planets closest to the Sun are Mercury, Mars, Venus, and Earth - they move around it in different paths.\n",
      "3. Neptune and Uranus are gas giants outside our solar system's orbit, moving away from the Sun slowly.\n",
      "4. Pluto is now classified as a dwarf planet, although it's still being studied by astronomers.\n",
      "5. The Kuiper Belt contains many small icy objects like Eris and Haumea - they're thought to be remnants of the early days of our solar system.\n"
     ]
    }
   ],
   "source": [
    "response = chain.invoke({'school': 'primary', 'topics': 'solar system', 'points': 5})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Here's a brief overview of the solar system:\\n\\n1. The Sun is at the center, and it makes up 99% of the total mass.\\n2. The four planets closest to the Sun are Mercury, Mars, Venus, and Earth - they move around it in different paths.\\n3. Neptune and Uranus are gas giants outside our solar system's orbit, moving away from the Sun slowly.\\n4. Pluto is now classified as a dwarf planet, although it's still being studied by astronomers.\\n5. The Kuiper Belt contains many small icy objects like Eris and Haumea - they're thought to be remnants of the early days of our solar system.\", additional_kwargs={}, response_metadata={'model': 'llama3.2:1b', 'created_at': '2025-01-03T03:54:39.5592872Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 9844633100, 'load_duration': 2730894400, 'prompt_eval_count': 46, 'prompt_eval_duration': 517000000, 'eval_count': 136, 'eval_duration': 5238000000}, id='run-ddb89d81-19d0-44b0-af98-f502b022e0f4-0', usage_metadata={'input_tokens': 46, 'output_tokens': 136, 'total_tokens': 182})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's what you asked for:\n",
      "\n",
      "1. **Eight planets**: The Solar System has eight planets, starting from Mercury and going up to Neptune.\n",
      "2. **Sun is at center**: Our star, the Sun, is at the very center of our Solar System.\n",
      "3. **Venus and Earth are first**: Venus and Earth are usually the first two planets you'd see when looking out into space.\n",
      "4. **Mars and Jupiter next**: Mars is the second planet from the Sun, followed by the gas giant Jupiter.\n",
      "5. **Saturn's rings shine bright**: Saturn has beautiful rings that are made of ice and rock particles.\n"
     ]
    }
   ],
   "source": [
    "chain = template | llm | StrOutputParser()\n",
    "response = chain.invoke({'school': 'primary', 'topics': 'solar system', 'points': 5})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chaining Runnables (Chain Multiple Runnables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['points', 'school', 'topics'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['school'], input_types={}, partial_variables={}, template='You are {school} teacher. You answer in short sentences.'), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['points', 'topics'], input_types={}, partial_variables={}, template='tell me about the {topics} in {points} points'), additional_kwargs={})])\n",
       "| ChatOllama(model='llama3.2:1b', base_url='http://localhost:11434')\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text is moderately complex, requiring some basic understanding of language and grammar.\n"
     ]
    }
   ],
   "source": [
    "analysis_prompt = ChatPromptTemplate.from_template('''analyze the following text: {response}.\n",
    "                                                   You need to tell how difficult the text is to understand.\n",
    "                                                   Answer in one sentence only.\n",
    "                                                   ''')\n",
    "fact_check_chain = analysis_prompt | llm | StrOutputParser()\n",
    "output = fact_check_chain.invoke({'response': 'The sun is a star.'})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text is written at a simple 6th-grade reading level, with short sentences and basic vocabulary, making it easily understandable for a general audience.\n"
     ]
    }
   ],
   "source": [
    "composed_chain = {\"response\": chain} | analysis_prompt | llm | StrOutputParser()\n",
    "output = composed_chain.invoke({'school': 'phd', 'topics': 'solar system', 'points': 5})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel LCEL Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The solar system consists of eight planets, dwarf planets, and other objects:\n",
      "\n",
      "* The four inner planets (Mercury, Venus, Earth, and Mars) orbit around the Sun.\n",
      "* The outer planets (Jupiter, Saturn, Uranus, and Neptune) are much larger and have unique characteristics.\n"
     ]
    }
   ],
   "source": [
    "system = SystemMessagePromptTemplate.from_template('You are {school} teacher. You answer in short sentences.')\n",
    "\n",
    "question = HumanMessagePromptTemplate.from_template('tell me about the {topics} in {points} points')\n",
    "\n",
    "messages = [system, question]\n",
    "\n",
    "fact_chain = template | llm | StrOutputParser()\n",
    "\n",
    "output = fact_chain.invoke({'school': 'phd', 'topics': 'solar system', 'points': 2})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planets orbit around the sun,\n",
      "Mars to Jupiter, they're all done.\n"
     ]
    }
   ],
   "source": [
    "question = HumanMessagePromptTemplate.from_template('write a poem on {topics} in {sentences} lines.')\n",
    "\n",
    "messages = [system, question]\n",
    "template = ChatPromptTemplate(messages)\n",
    "poem_chain = template | llm | StrOutputParser()\n",
    "\n",
    "output = poem_chain.invoke({'school': 'phd', 'topics': 'solar system', 'sentences': 2})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableParallel(fact = fact_chain, poem = poem_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = chain.invoke({'school': 'phd', 'topics': 'solar system', 'points': 2, 'sentences': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's an overview of the solar system:\n",
      "\n",
      "• Our solar system consists of eight planets, including Mercury, Mars, Earth, and Jupiter, orbiting around the Sun.\n",
      "\n",
      "• The four outer planets (Jupiter, Saturn, Uranus, and Neptune) are gas giants with diverse compositions and unique features.\n",
      "\n",
      "\n",
      "\n",
      "Planets orbit Earth, a celestial show,\n",
      "Stars and galaxies dance, as the universe grows.\n"
     ]
    }
   ],
   "source": [
    "print(output['fact'])\n",
    "print('\\n\\n')\n",
    "print(output['poem'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chain Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Negative.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"Given the user review below, classify it as either being about `Positive` or `Negative`.'\n",
    "            Do not respond with moren than one word.\n",
    "\n",
    "            Review: {review}\n",
    "            Classification:\"\"\"\n",
    "\n",
    "template = ChatPromptTemplate.from_template(prompt)\n",
    "\n",
    "chain = template | llm | StrOutputParser()\n",
    "\n",
    "review = \"Thank you so much for providing such a great platform for learning. I am really happy with the service.\"\n",
    "\n",
    "# review = \"This service is the worst I have ever seen. I will never use it again.\"\n",
    "\n",
    "chain.invoke({'review': review})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_review = \"\"\"\n",
    "You are an expert in writing reply for positive reviews.\n",
    "You need to encourage the user to share their experience in social media.\n",
    "Review: {review}\n",
    "Answer:\"\"\"\n",
    "\n",
    "positive_prompt = ChatPromptTemplate.from_template(positive_review)\n",
    "\n",
    "positive_chain = positive_prompt | llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_review = \"\"\"\n",
    "You are an expert in writing reply for negative reviews.\n",
    "You need first to apologize for the inconvenience caused to the users.\n",
    "You need to encourage the user to share their concerns on following email: 'letstalk@abc.xyz'\n",
    "Review: {review}\n",
    "Answer:\"\"\"\n",
    "\n",
    "negative_prompt = ChatPromptTemplate.from_template(negative_review)\n",
    "\n",
    "negative_chain = negative_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route(info):\n",
    "  if 'positive' in info['sentiment'].lower():\n",
    "    return positive_chain\n",
    "  else:\n",
    "    return negative_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# route({'sentiment': 'negative'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_chain = {'sentiment': chain, 'review': lambda x: x['review']} | RunnableLambda(route) | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a potential response:\n",
      "\n",
      "Dear valued customer,\n",
      "\n",
      "I want to start by apologizing for the disappointing experience you had with our service. We regret that we failed to meet your expectations, and for that, we are truly sorry.\n",
      "\n",
      "We understand that choosing a service can be a frustrating and costly decision, and it's unacceptable that ours fell short of your needs. Please know that this is not a reflection on the hard work and dedication of our team.\n",
      "\n",
      "In an effort to prevent similar issues in the future, we would like to thank you for taking the time to share your feedback with us. Your input will be invaluable in helping us improve our services and ensure that others have a better experience.\n",
      "\n",
      "If you would be willing, could you please reach out to us at letstalk@abc.xyz so we can discuss how we can make things right? We are committed to providing excellent service and value to all our customers.\n",
      "\n",
      "Thank you for your time, and we hope to have the opportunity to serve you better in the future.\n",
      "\n",
      "Best regards,\n",
      "[Your Name]\n",
      "\n",
      "This response acknowledges the user's negative experience, apologizes for any inconvenience caused, and shows appreciation for their feedback. It also encourages them to share their concerns so that the company can learn from their experiences and improve its services.\n"
     ]
    }
   ],
   "source": [
    "# review = \"Thank you so much for providing such a great platform for learning. I am really happy with the service.\"\n",
    "\n",
    "review = \"This service is the worst I have ever seen. I will never use it again.\"\n",
    "\n",
    "output = full_chain.invoke({'review': review})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Custom Chain Runnables with RunnablePassthrough and RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_counts(text):\n",
    "  return len(text)\n",
    "\n",
    "def word_counts(text):\n",
    "  return len(text.split())\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template('Explain these inputs in 5 sentences: {input1} and {input2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These are two distinct concepts that need clarification.\n",
      "\n",
      "The sun is indeed a star, but it's the center of our solar system. It's a massive ball of hot, glowing gas that generates its own light and heat through nuclear reactions in its core. The sun is a massive celestial body that supports life on Earth and is the primary source of energy for our planet.\n",
      "\n",
      "On the other hand, the moon is not technically a satellite, but rather a natural satellite that orbits the Earth. It's a rocky, airless body that was once part of the Earth's mantle but was broken off and later coaxed into orbit by the gravitational force of the Earth. The moon is about 2,159 miles (3,475 kilometers) away from our planet and has its own unique characteristics, such as tides and phases.\n",
      "\n",
      "Here are a few key differences between a star like the sun and objects in space that are often referred to as \"sats\" or satellites:\n",
      "\n",
      "* A star is a massive ball of hot gas with intense energy.\n",
      "* Objects in space that are not stars (like planets, moons, asteroids) do not generate their own light and heat through nuclear reactions.\n",
      "* Satellites, on the other hand, are typically artificial objects designed to orbit a celestial body. They can be man-made or unmanned, but they're often referred to as \"sats\" due to their connection to satellites in space.\n",
      "\n",
      "To summarize:\n",
      "\n",
      "* The sun is a star.\n",
      "* The moon is not a satellite, but rather a natural satellite that orbits the Earth.\n",
      "* Satellites are artificial objects designed to orbit celestial bodies.\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | StrOutputParser() \n",
    "\n",
    "output = chain.invoke({'input1': 'The sun is a star.', 'input2': 'The moon is a satellite.'})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'char_counts': 715, 'word_counts': 124, 'output': 'The statement \"The sun is a star\" refers to the fact that the sun is a massive ball of hot, glowing gas that is composed primarily of hydrogen and helium. This composition is similar to other stars in our solar system, which are also known as G-type main-sequence stars. In contrast, the moon is not considered a star but rather a natural satellite or asteroid that orbits around the Earth due to its own gravity. The moon\\'s mass and composition are significantly different from those of the sun, with a much lower density and different elemental makeup. This distinct difference in characteristics means that the sun and the moon do not possess the same level of nuclear fusion or energy production as other stars.'}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | StrOutputParser() | {'char_counts': RunnableLambda(char_counts), 'word_counts': RunnableLambda(word_counts), 'output': RunnablePassthrough()}\n",
    "\n",
    "output = chain.invoke({'input1': 'The sun is a star.', 'input2': 'The moon is a satellite.'})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Chain using @chain decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a brief overview of the solar system in two points:\n",
      "\n",
      "* The Sun is at the center, making up most of the solar system's mass.\n",
      "* There are eight planets (Mercury to Neptune) orbiting around the Sun in our own solar system.\n",
      "\n",
      "\n",
      "\n",
      "The sun is at the center bright,\n",
      "Orbiting planets, a celestial sight.\n"
     ]
    }
   ],
   "source": [
    "@chain\n",
    "def custom_chain(params):\n",
    "  return {\n",
    "    'fact': fact_chain.invoke(params),\n",
    "    'poem': poem_chain.invoke(params),\n",
    "  }\n",
    "\n",
    "params = {'school': 'primary', 'topics': 'solar system', 'points': 2, 'sentences': 2}\n",
    "\n",
    "output = custom_chain.invoke(params)\n",
    "\n",
    "print(output['fact'])\n",
    "print('\\n\\n')\n",
    "print(output['poem'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

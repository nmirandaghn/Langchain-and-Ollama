{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language models output text. But there are times where you want to get more structured information than just text back\n",
    "\n",
    "Output parsers are classes that help structure language model responses. There are two main methods an output parser must implement:\n",
    "\n",
    "- **Get format instructions**: A method which returns a string containing instructions for how the output of a language model should be formatted.\n",
    "- **Parse**: A method which takes in a string (assumed to be the response from a language model) and parses it into some structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Output Parsing\n",
    "    - StrOutputParser\n",
    "    - JsonOutputParser\n",
    "    - CSV Output Parser\n",
    "    - Datatime Output Parser\n",
    "    - Structured Output Parser (Pydanitc or Json)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Pydantinc` Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('./../.env')\n",
    "\n",
    "# langfuse or opik"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "from langchain_core.prompts import (\n",
    "                                        SystemMessagePromptTemplate,\n",
    "                                        HumanMessagePromptTemplate,\n",
    "                                        ChatPromptTemplate,\n",
    "                                        PromptTemplate\n",
    "                                        )\n",
    "\n",
    "base_url = \"http://localhost:11434\"\n",
    "model = 'llama3.2:3b'\n",
    "\n",
    "llm = ChatOllama(base_url=base_url, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain_core.output_parsers import PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Joke(BaseModel):\n",
    "  \"\"\"Joke to tell user\"\"\"\n",
    "  setup: str = Field(description=\"Setup of the joke\")\n",
    "  punchline: str = Field(description=\"Punchline of the joke\")\n",
    "  rating: Optional[int] = Field(description=\"Rating of the joke is from 1 to 10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "joke_data = {\n",
    "    \"setup\": \"Why did the chicken cross the road?\",\n",
    "    \"punchline\": \"To get to the other side!\",\n",
    "    \"rating\": 8\n",
    "}\n",
    "joke = Joke(**joke_data)  # Esto crea una instancia de Joke y valida los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Joke(setup='Why did the chicken cross the road?', punchline='To get to the other side!', rating=8)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joke"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PydanticOutputParser(pydantic_object=<class '__main__.Joke'>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "\n",
    "parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"Joke to tell user\", \"properties\": {\"setup\": {\"description\": \"Setup of the joke\", \"title\": \"Setup\", \"type\": \"string\"}, \"punchline\": {\"description\": \"Punchline of the joke\", \"title\": \"Punchline\", \"type\": \"string\"}, \"rating\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}], \"description\": \"Rating of the joke is from 1 to 10\", \"title\": \"Rating\"}}, \"required\": [\"setup\", \"punchline\", \"rating\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "instructions = parser.get_format_instructions()\n",
    "print(instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "  template = '''\n",
    "  Answer the query with a joke. Here is the formatting instructions: {format_instructions}\n",
    "  \n",
    "  Query: {query}\n",
    "  Answer:''',\n",
    "  input_variables = ['query'],\n",
    "  partial_variables = {'format_instructions': parser.get_format_instructions()})\n",
    "\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"setup\": \"Why do developers love stack Overflow?\", \"punchline\": \"Because it's the only place where they can always find the issue!\", \"rating\": null}\n"
     ]
    }
   ],
   "source": [
    "output = chain.invoke({'query': \"Tell me a joke about developers\"})\n",
    "\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup='Why did the dog go to the vet?' punchline='Because he was feeling ruff!' rating=8\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | parser\n",
    "output = chain.invoke({'query': \"Tell me a joke about dogs\"})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing with `.with_structured_output()` method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the dog go to the vet?\n",
      "\n",
      "Because he was feeling ruff!\n",
      "\n",
      "(I hope that one made you howl with laughter!)\n"
     ]
    }
   ],
   "source": [
    "output = llm.invoke(\"Tell me a joke about dogs\")\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_llm = llm.with_structured_output(Joke)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setup='Why did the dog go to the vet?' punchline='Because he was feeling ruff!' rating=8\n"
     ]
    }
   ],
   "source": [
    "output = structured_llm.invoke(\"Tell me a joke about dogs\")\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `JSON` Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"description\": \"Joke to tell user\", \"properties\": {\"setup\": {\"description\": \"Setup of the joke\", \"title\": \"Setup\", \"type\": \"string\"}, \"punchline\": {\"description\": \"Punchline of the joke\", \"title\": \"Punchline\", \"type\": \"string\"}, \"rating\": {\"anyOf\": [{\"type\": \"integer\"}, {\"type\": \"null\"}], \"description\": \"Rating of the joke is from 1 to 10\", \"title\": \"Rating\"}}, \"required\": [\"setup\", \"punchline\", \"rating\"]}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "parser = JsonOutputParser(pydantic_object=Joke)\n",
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"setup\": \"Why did the dog go to the vet?\", \"punchline\": \"Because he was feeling ruff!\", \"rating\": 8}\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "  template = '''\n",
    "  Answer the query with a joke. Here is the formatting instructions: {format_instructions}\n",
    "  \n",
    "  Query: {query}\n",
    "  Answer:''',\n",
    "  input_variables = ['query'],\n",
    "  partial_variables = {'format_instructions': parser.get_format_instructions()})\n",
    "\n",
    "chain = prompt | llm\n",
    "output = chain.invoke({'query': \"Tell me a joke about dogs\"})\n",
    "print(output.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'setup': 'Why did the dog go to the vet?', 'punchline': 'Because he was feeling ruff!', 'rating': 8}\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | parser\n",
    "output = chain.invoke({'query': \"Tell me a joke about dogs\"})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your response should be a list of comma separated values, eg: `foo, bar, baz` or `foo,bar,baz`\n"
     ]
    }
   ],
   "source": [
    "# value1, value2, value3, so on\n",
    "from langchain_core.output_parsers import CommaSeparatedListOutputParser\n",
    "\n",
    "parser = CommaSeparatedListOutputParser()\n",
    "\n",
    "print(parser.get_format_instructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instructions = parser.get_format_instructions()\n",
    "prompt = PromptTemplate(\n",
    "  template = '''\n",
    "  Answer the query with a list of items separated by commas. Here is the formatting instructions: {format_instructions}\n",
    "  \n",
    "  Query: {query}\n",
    "  Answer:''',\n",
    "  input_variables = ['query'],\n",
    "  partial_variables = {'format_instructions': format_instructions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dog', 'cat', 'elephant', 'lion', 'tiger', 'bear', 'monkey', 'giraffe', 'zebra', 'kangaroo']\n"
     ]
    }
   ],
   "source": [
    "chain = prompt | llm | parser\n",
    "\n",
    "output = chain.invoke({'query': \"Tell me a list of animals\"})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datetime Output Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write a datetime string that matches the following pattern: '%Y-%m-%dT%H:%M:%S.%fZ'.\n",
      "\n",
      "Examples: 0567-05-09T14:25:04.494270Z, 1751-10-06T11:00:09.319664Z, 1825-04-18T07:43:36.735641Z\n",
      "\n",
      "Return ONLY this string, no other words!\n"
     ]
    }
   ],
   "source": [
    "from langchain.output_parsers import DatetimeOutputParser\n",
    "\n",
    "parser = DatetimeOutputParser()\n",
    "format_instructions = parser.get_format_instructions()\n",
    "\n",
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instructions = parser.get_format_instructions()\n",
    "prompt = PromptTemplate(\n",
    "  template = '''\n",
    "  Answer the query with a date. Here is the formatting instructions: {format_instructions}\n",
    "  \n",
    "  Query: {query}\n",
    "  Answer:''',\n",
    "  input_variables = ['query'],\n",
    "  partial_variables = {'format_instructions': format_instructions})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt | llm | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1492-08-10 09:00:00\n"
     ]
    }
   ],
   "source": [
    "output = chain.invoke({'query': \"When was America discovered?\"})\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
